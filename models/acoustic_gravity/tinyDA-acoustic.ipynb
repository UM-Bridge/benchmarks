{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion for a coupled acoustic-gravity system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running `pip install tinyda ray' \n",
    "\n",
    "### Problem setup\n",
    "\n",
    "Let $\\varphi$ be the potential for the flow velocity, it is solution to \n",
    "\\begin{align}\\label{eq:forwardmodel}\n",
    "    \\frac{\\partial^2 \\varphi}{\\partial t^2}\n",
    "    - c^2 \\Delta \\varphi \n",
    "    + g \\frac{\\partial \\varphi}{\\partial z}\n",
    "    = 0,  \\quad \\text{ in } \\Omega,\n",
    "    \\\\\n",
    "    \\frac{\\partial^2 \\varphi}{\\partial t^2}\n",
    "    + g \\frac{\\partial \\varphi}{\\partial z} \n",
    "    = 0, \\quad \\text{ on } \\Gamma_s,\n",
    "    \\\\\n",
    "    \\nabla \\varphi \\cdot {\\bf n}\n",
    "    = u_b, \\quad \\text{ on } \\Gamma_b,\n",
    "\\end{align}\n",
    "where $c$ is the (constant) sound speed, $g$ is the gravity acceleration, ${\\bf n}$ is the outwards unit vector normal to the seabed $\\Gamma_b$ and $u_b$ is the seabed velocity.\n",
    "The fluid displacement $u$ is related to the potential by $u = \\nabla \\varphi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal, norm, rv_continuous, wasserstein_distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "import tinyDA as tda\n",
    "import umbridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising UM-Bridge\n",
    "Before running the following cell, the model Docker image must be started from a system terminal using\n",
    "\n",
    "`docker run -it -p 4242:4242 acousticgravity`\n",
    "\n",
    "The Dockerfile can be found in the acousticgracity branch on UM-Bridge benchmarks. If not just running on a local machine replace `localhost` with the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the UM-Bridge model.\n",
    "umbridge_model = umbridge.HTTPModel('http://localhost:4242', \"forward\")\n",
    "\n",
    "# wrap the UM-Bridge model in the tinyDA UM-Bridge interface.\n",
    "my_model = tda.UmBridgeModel(umbridge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = umbridge_model.get_input_sizes()[0] #the input is the value of f(x) at each grid point\n",
    "ny = umbridge_model.get_output_sizes()[0] #the outout is a time series of the pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scale = 5.0\n",
    "eps = 1e-6\n",
    "decay_rate = 10\n",
    "\n",
    "x = np.linspace(0, nx - 1, nx).reshape(-1, 1)\n",
    "\n",
    "def rbf_covariance(grid, length_scale, variance=1.0):\n",
    "    dists = cdist(grid, grid, 'euclidean')\n",
    "    return variance * np.exp(-0.5 * (dists / length_scale) ** 2)\n",
    "\n",
    "cov = rbf_covariance(x, length_scale)\n",
    "cov += eps * np.eye(nx)\n",
    "mean = np.zeros(nx)\n",
    "my_prior = multivariate_normal(mean=mean, cov=cov)\n",
    "\n",
    "def smooth_cut(x, x0, width, k):\n",
    "    step1 = 1 / (1 + np.exp(-k * (x - (x0 - width / 2))))\n",
    "    step2 = 1 / (1 + np.exp(-k * (x - (x0 + width / 2))))\n",
    "    return step1 - step2\n",
    "\n",
    "cut = smooth_cut(x.flatten(), nx / 2, nx * (1 - 14 / nx), decay_rate)\n",
    "\n",
    "sample = my_prior.rvs()\n",
    "\n",
    "def restriction(sampin):\n",
    "    field_cut = sampin * cut\n",
    "    return (field_cut > eps).astype(int)\n",
    "\n",
    "sample = restriction(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.set_xticks([i for i in range(nx)])\n",
    "ax.grid()\n",
    "ax.plot(sample,label='sample')\n",
    "ax.plot(cut,label='smooth cut')\n",
    "ax.plot(sample * cut, label='cut sample')\n",
    "ax.legend()\n",
    "ax.set_title(\"Binary Level Set Sample from Gaussian Random Field\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data for input 0.5\n",
    "# Input is a 15km wide fault centered around x\n",
    "# Domain size is 150km\n",
    "exact = np.zeros(nx)\n",
    "exact[20:25]=1\n",
    "d_true = my_model(exact)\n",
    "\n",
    "# add some noise to the model output\n",
    "sigma_noise = 0.001\n",
    "d = d_true + np.random.normal(loc=0, scale=sigma_noise, size=ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,2))\n",
    "ax.set_title('Input')\n",
    "x=np.linspace(0,nx, nx)\n",
    "t=np.linspace(0,10, ny)\n",
    "ax.plot(t,d_true, label='Noise-free output')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot only model output as the input is a simple 1D location so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model output\n",
    "fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(12,4))\n",
    "\n",
    "# plot the time series of pressure\n",
    "t = np.linspace(0,10,ny)\n",
    "ax[0].set_title('Pressure')\n",
    "ax[0].plot(t,d_true, label='Noise-free input')\n",
    "ax[0].plot(t,d, label='Noisy input')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_title('Pressure')\n",
    "samples = []\n",
    "inputs=[]\n",
    "# Plot 10 random samples\n",
    "for x in range(15):\n",
    "    log = my_prior.rvs()\n",
    "    log = restriction(log)\n",
    "    d_sample = my_model(log)\n",
    "    ax[1].plot(t, d_sample, label='samples')\n",
    "    ax[2].plot(range(len(log)), log, label='input')\n",
    "    samples.append(d_sample)\n",
    "    inputs.append(log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wasserstein_loglike():\n",
    "    def __init__(self, ground_truth):\n",
    "        self.ground_truth = ground_truth\n",
    "    \n",
    "    def loglike(self,x):\n",
    "        return -100 * wasserstein_distance(x,self.ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set the covariance of the likelihood.\n",
    "# sigma = 0.125\n",
    "# cov_likelihood = sigma**2*np.eye(d.shape[0])\n",
    "# my_loglike = tda.GaussianLogLike(d, cov_likelihood)\n",
    "my_loglike = wasserstein_loglike(d_true)\n",
    "\n",
    "# initialise the Posterior\n",
    "my_posterior = tda.Posterior(my_prior, my_loglike, my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_sample in samples:\n",
    "    print(np.exp(my_loglike.loglike(d_sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model output\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12,4))\n",
    "\n",
    "ax[1].set_title('Pressure')\n",
    "# Plot 10 random samples\n",
    "for i in range(5):\n",
    "    #log = my_prior.rvs()\n",
    "    #d_sample = my_model(log)\n",
    "    log = inputs[i]\n",
    "    print(log)\n",
    "    ax[0].plot(log)\n",
    "    ax[0].plot(28,0.9, 'x', color='red')\n",
    "    ax[1].plot(t, samples[i], label=f'samples {i}')\n",
    "    #samples.append(d_sample)\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Crank-Nicolson with cutoff and levelset\n",
    "class CrankNicolsonWithProjection(tda.CrankNicolson):\n",
    "    def __init__(self, scaling, adaptive):\n",
    "        super().__init__(scaling=scaling, adaptive=adaptive)\n",
    "\n",
    "    def make_proposal(self, link):\n",
    "        # make a pCN proposal.\n",
    "        return np.sqrt(\n",
    "            1 - self.scaling**2\n",
    "        ) * link.parameters + self.scaling * restriction(np.random.multivariate_normal(\n",
    "            self._mean, self.C\n",
    "        ))\n",
    "\n",
    "# preconditioned Crank-Nicolson\n",
    "pcn_scaling = 1.0\n",
    "pcn_adaptive = False\n",
    "my_proposal = CrankNicolsonWithProjection(scaling=pcn_scaling, adaptive=pcn_adaptive)\n",
    "\n",
    "# # random walk Metropolis\n",
    "#rwmh_cov = np.eye(nx)\n",
    "#rmwh_scaling = 0.1\n",
    "#rwmh_adaptive = False\n",
    "#my_proposal = tda.GaussianRandomWalk(C=rwmh_cov, scaling=rmwh_scaling, adaptive=rwmh_adaptive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes, iteration number is small for the given problem; Choose a larger number for real applications.\n",
    "my_chains = tda.sample(my_posterior, my_proposal, iterations=10, n_chains=2, force_sequential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the tinyDA chains to an ArViz InferenceData object.\n",
    "idata = tda.to_inference_data(my_chains, burnin=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display posterior summary statistics.\n",
    "info = az.summary(idata)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior kernel densities and traces.\n",
    "az.plot_trace(idata, figsize=(18, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the parameters from the chains.\n",
    "parameters = [link.parameters for link in my_chains['chain_0'][2001:] + my_chains['chain_1'][2001:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some posterior draws of the model input and output.\n",
    "n_samples = 1000\n",
    "ids = np.random.randint(0, len(parameters), n_samples)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,4))\n",
    "\n",
    "# plot the output pressure\n",
    "ax.set_title('Pressure')\n",
    "ax.plot(np.linspace(0,1,ny), d)\n",
    "for i in ids:\n",
    "    ax.plot(np.linspace(0,1,ny), my_model(parameters[i]), c='k', alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,2))\n",
    "ax.set_title('Input')\n",
    "x=np.linspace(0,nx, nx)\n",
    "t=np.linspace(0,10, ny)\n",
    "#ax.plot(x,exact, label='Noise-free input')\n",
    "ax.plot(t,d_true, label='Noise-free output')\n",
    "ax.legend()\n",
    "\n",
    "exact = np.zeros(nx)\n",
    "#exact[int(nx/2 - 6):int(nx/2 + 5)]=1\n",
    "exact[20:25]=1\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,3))\n",
    "ax.set_xticks([i for i in range(44)])\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(exact)\n",
    "\n",
    "x = range(len(info))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, info['mean'], 'o')  # x = index, y = mean\n",
    "plt.xticks(x, info.index, rotation=90)  # Show variable names on x-axis\n",
    "plt.ylabel('Mean')\n",
    "plt.xlabel('Variable')\n",
    "plt.title('Posterior Means')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential MC\n",
    "\n",
    "I've tried out this particle filter on an example they give. Laura, does the package contain anything useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfilter import ParticleFilter, independent_sample, squared_error\n",
    "from scipy.stats import norm, gamma, uniform \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(pf, ys, inputs=None):\n",
    "    \"\"\"Apply filter pf to a series of observations (time_steps, h)  and return a dictionary:    \n",
    "        particles: an array of particles (time_steps, n, d)\n",
    "        weights: an array of weights (time_steps,)        \n",
    "    \"\"\"\n",
    "\n",
    "    states = []\n",
    "    pf.init_filter()  # reset\n",
    "    for i,y in enumerate(ys):\n",
    "        if inputs is None:\n",
    "            pf.update(y)\n",
    "        else:\n",
    "            pf.update(y, **inputs[i])\n",
    "            \n",
    "        states.append([pf.transformed_particles, np.array(pf.weights)])\n",
    "    return {\n",
    "        name: np.array([s[i] for s in states])\n",
    "        for i, name in enumerate([\"particles\", \"weights\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_particles(x, y, yn, states):\n",
    "    \"\"\"Plot a 1D tracking result as a line graph with overlaid\n",
    "    scatterplot of particles. Particles are sized according to\n",
    "    normalised weight at each step.\n",
    "    \n",
    "        x: time values\n",
    "        y: original (uncorrupted) values\n",
    "        yn: noisy (observed) values\n",
    "        states: dictionary return from apply_pfilter        \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, label='True', lw=1)\n",
    "    ax.plot(x, yn, label='Noisy', lw=2)\n",
    "    \n",
    "    particles = states[\"particles\"]\n",
    "    ws = states[\"weights\"]    \n",
    "    means = np.sum(particles[:,:,0] * ws, axis=1)\n",
    "    \n",
    "    dev = (means - (particles[:,:,0]).T).T**2\n",
    "    var = np.sum(ws * dev, axis=1)  / 1-np.sum(ws**2)  # unbiased variance\n",
    "    stds = np.sqrt(var)\n",
    "    \n",
    "    ax.plot(x, means, 'C4', label='Mean est.', lw=4)\n",
    "    ax.fill_between(x, means-stds, means+stds, color='C4', alpha=0.5, label='Std.')\n",
    "    ax.scatter(np.tile(x, (len(particles[0]),1)).ravel(), particles[:,:,0].T, s=ws*1000/np.sqrt(len(ws)),\n",
    "                alpha=0.15, label='Particles')\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Observed\")\n",
    "    ax.legend()\n",
    "    \n",
    "def filter_plot(x, y, yn, pf, inputs=None):\n",
    "    \"\"\"Apply a filter to yn, and plot the results using plot_particles()\"\"\"\n",
    "    states = apply_filter(pf, yn, inputs)\n",
    "    plot_particles(x, y, yn, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy sine wave data\n",
    "x = np.linspace(0, 100, 100)\n",
    "y = np.cos(x/4.0) + x * 0.05\n",
    "yn = y + np.random.normal(0,0.5,x.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, label='True', lw=1)\n",
    "ax.plot(x, yn, label='Noisy', lw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No dynamics\n",
    "# just diffusion on x\n",
    "prior_fn = lambda n: np.random.normal(0,1,(n,1))\n",
    "dt = 0.05\n",
    "noise = 0.15\n",
    "sigma = 1.5\n",
    "\n",
    "pf = ParticleFilter(prior_fn = prior_fn, \n",
    "                    observe_fn = lambda x:  x,  \n",
    "                    dynamics_fn=lambda x:   x ,\n",
    "                    n_particles=250, \n",
    "                    noise_fn = lambda x: x + np.random.normal(0, noise, x.shape),\n",
    "                    weight_fn = lambda x,y : squared_error(x, y, sigma=sigma),\n",
    "                    resample_proportion=0.01)\n",
    "\n",
    "filter_plot(x, y, yn, pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level set priors\n",
    "\n",
    "Some samples from 2D and 1D level sets. Comparing cut of a 2D level set and 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from FyeldGenerator import generate_field\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper that generates power-law power spectrum\n",
    "def Pkgen(n):\n",
    "    def Pk(k):\n",
    "        return np.power(k, -n)\n",
    "    return Pk\n",
    "\n",
    "# Draw samples from a normal distribution\n",
    "def distrib(shape):\n",
    "    a = np.random.normal(loc=0, scale=1, size=shape)\n",
    "    b = np.random.normal(loc=0, scale=1, size=shape)\n",
    "    return a + 1j * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (512, 512)\n",
    "field1 = generate_field(distrib, Pkgen(2), shape)\n",
    "field2 = generate_field(distrib, Pkgen(4), shape)\n",
    "field3 = generate_field(distrib, Pkgen(6), shape)\n",
    "field4 = generate_field(distrib, Pkgen(2), shape)\n",
    "field5 = generate_field(distrib, Pkgen(4), shape)\n",
    "field6 = generate_field(distrib, Pkgen(6), shape)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\n",
    "ax[0,0].imshow(field1, cmap=\"jet\")\n",
    "ax[0,1].imshow(field2, cmap=\"jet\")\n",
    "ax[0,2].imshow(field3, cmap=\"jet\")\n",
    "ax[1,0].imshow(field1<0, cmap=\"jet\")\n",
    "ax[1,1].imshow(field2<0, cmap=\"jet\")\n",
    "ax[1,2].imshow(field3<0, cmap=\"jet\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\n",
    "ax[0,0].imshow(field4, cmap=\"jet\")\n",
    "ax[0,1].imshow(field5, cmap=\"jet\")\n",
    "ax[0,2].imshow(field6, cmap=\"jet\")\n",
    "ax[1,0].imshow(field4<0, cmap=\"jet\")\n",
    "ax[1,1].imshow(field5<0, cmap=\"jet\")\n",
    "ax[1,2].imshow(field6<0, cmap=\"jet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross section of a 2D randomfield\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\n",
    "\n",
    "ax[0].plot(field1[0,:]<0)\n",
    "ax[1].plot(field2[0,:]<0)\n",
    "ax[2].plot(field3[0,:]<0)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\n",
    "\n",
    "ax[0].plot(field4[0,:]<0)\n",
    "ax[1].plot(field5[0,:]<0)\n",
    "ax[2].plot(field6[0,:]<0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (512, 1)\n",
    "field1 = generate_field(distrib, Pkgen(2), shape)\n",
    "field2 = generate_field(distrib, Pkgen(4), shape)\n",
    "field3 = generate_field(distrib, Pkgen(6), shape)\n",
    "field4 = generate_field(distrib, Pkgen(2), shape)\n",
    "field5 = generate_field(distrib, Pkgen(4), shape)\n",
    "field6 = generate_field(distrib, Pkgen(6), shape)\n",
    "\n",
    "# 1D levelset\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\n",
    "\n",
    "ax[0,0].plot(field1)\n",
    "ax[0,1].plot(field2)\n",
    "ax[0,2].plot(field3)\n",
    "ax[1,0].plot(field1<0)\n",
    "ax[1,1].plot(field2<0)\n",
    "ax[1,2].plot(field3<0)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(12,8))\n",
    "\n",
    "ax[0,0].plot(field4)\n",
    "ax[0,1].plot(field5)\n",
    "ax[0,2].plot(field6)\n",
    "ax[1,0].plot(field4<0)\n",
    "ax[1,1].plot(field5<0)\n",
    "ax[1,2].plot(field6<0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
