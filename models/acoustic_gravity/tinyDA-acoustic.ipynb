{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tinyDA can be pip installed\n",
    "\n",
    "### Problem setup\n",
    "\n",
    "In this example we solve..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray module not found. Multiprocessing features are not available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "import tinyDA as tda\n",
    "import umbridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising UM-Bridge\n",
    "Before running the following cell, the model Docker image must be started from a system terminal using \n",
    "`docker run -it -p 4242:4242 acousticgravity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the UM-Bridge model.\n",
    "umbridge_model = umbridge.HTTPModel('http://localhost:4242', \"forward\")\n",
    "\n",
    "# wrap the UM-Bridge model in the tinyDA UM-Bridge interface.\n",
    "pre = lambda x: np.array(x)\n",
    "my_model = tda.UmBridgeModel(umbridge_model, pre=pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of inputs and outputs.\n",
    "nx = umbridge_model.get_input_sizes()[0] #the input is the location in x of the jump discontinuity\n",
    "ny = umbridge_model.get_output_sizes()[0] #the outout is a time series of the pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert NumPy array to standard UM-Bridge input.\n",
    "parameters = np.ndarray(1)\n",
    "parameters[0] = 0.5\n",
    "umbridge_input = [pre(parameters).tolist()]\n",
    "\n",
    "# send converted model input the the UM-Bridge model.\n",
    "umbridge_output = umbridge_model(umbridge_input)\n",
    "\n",
    "# convert the UM-Bridge output back to a NumPy array.\n",
    "model_output = np.array(umbridge_output).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the prior mean and covariance.\n",
    "mean_prior = np.zeros(nx)\n",
    "cov_prior = np.eye(nx)\n",
    "\n",
    "# set the covariance of the likelihood.\n",
    "sigma_noise = 0.1\n",
    "cov_likelihood = sigma_noise**2*np.eye(data.shape[0])\n",
    "\n",
    "# initialise the prior distribution and likelihood.\n",
    "my_prior = multivariate_normal(mean_prior, cov_prior)\n",
    "my_loglike = tda.GaussianLogLike(data, cov_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a draw from the prior and pass it through the model\n",
    "log_true = my_prior.rvs()\n",
    "\n",
    "print(log_true)\n",
    "\n",
    "d_true = umbridge_model([np.array(log_input).tolist()])\n",
    "\n",
    "# add some noise to the model output\n",
    "d = d_true + np.random.normal(loc=0, scale=sigma_noise, size=ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Posterior\n",
    "my_posterior = tda.Posterior(my_prior, my_loglike, umbridge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preconditioned Crank-Nicolson\n",
    "pcn_scaling = 0.1\n",
    "pcn_adaptive = True\n",
    "my_proposal = tda.CrankNicolson(scaling=pcn_scaling, adaptive=pcn_adaptive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes, iteration number is small for the given problem; Choose a larger number for real applications.\n",
    "my_chains = tda.sample(my_posterior, my_proposal, iterations=100, n_chains=1, force_sequential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the tinyDA chains to an ArViz InferenceData object.\n",
    "idata = tda.to_inference_data(my_chains, burnin=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display posterior summary statistics.\n",
    "az.summary(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior kernel densities and traces.\n",
    "az.plot_trace(idata)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the parameters from the chains.\n",
    "parameters = [link.parameters for link in my_chains['chain_0'][2001:] + my_chains['chain_1'][2001:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some posterior draws of the model input and output.\n",
    "n_samples = 1000\n",
    "ids = np.random.randint(0, len(parameters), n_samples)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "\n",
    "# plot the stiffness.\n",
    "ax[0].set_title('Stiffness')\n",
    "ax[0].plot(x, E(log_E_true))\n",
    "for i in ids:\n",
    "    ax[0].plot(x, E(parameters[i]), c='k', alpha=0.01)\n",
    "\n",
    "# plot the deflection\n",
    "ax[1].set_title('Deflection')\n",
    "ax[1].plot(x, d)\n",
    "for i in ids:\n",
    "    ax[1].plot(x, my_model(parameters[i]), c='k', alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfilter import ParticleFilter, independent_sample, squared_error\n",
    "from scipy.stats import norm, gamma, uniform \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(pf, ys, inputs=None):\n",
    "    \"\"\"Apply filter pf to a series of observations (time_steps, h)  and return a dictionary:    \n",
    "        particles: an array of particles (time_steps, n, d)\n",
    "        weights: an array of weights (time_steps,)        \n",
    "    \"\"\"\n",
    "\n",
    "    states = []\n",
    "    pf.init_filter()  # reset\n",
    "    for i,y in enumerate(ys):\n",
    "        if inputs is None:\n",
    "            pf.update(y)\n",
    "        else:\n",
    "            pf.update(y, **inputs[i])\n",
    "            \n",
    "        states.append([pf.transformed_particles, np.array(pf.weights)])\n",
    "    return {\n",
    "        name: np.array([s[i] for s in states])\n",
    "        for i, name in enumerate([\"particles\", \"weights\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_particles(x, y, yn, states):\n",
    "    \"\"\"Plot a 1D tracking result as a line graph with overlaid\n",
    "    scatterplot of particles. Particles are sized according to\n",
    "    normalised weight at each step.\n",
    "    \n",
    "        x: time values\n",
    "        y: original (uncorrupted) values\n",
    "        yn: noisy (observed) values\n",
    "        states: dictionary return from apply_pfilter        \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, label='True', lw=1)\n",
    "    ax.plot(x, yn, label='Noisy', lw=2)\n",
    "    \n",
    "    particles = states[\"particles\"]\n",
    "    ws = states[\"weights\"]    \n",
    "    means = np.sum(particles[:,:,0] * ws, axis=1)\n",
    "    \n",
    "    dev = (means - (particles[:,:,0]).T).T**2\n",
    "    var = np.sum(ws * dev, axis=1)  / 1-np.sum(ws**2)  # unbiased variance\n",
    "    stds = np.sqrt(var)\n",
    "    \n",
    "    ax.plot(x, means, 'C4', label='Mean est.', lw=4)\n",
    "    ax.fill_between(x, means-stds, means+stds, color='C4', alpha=0.5, label='Std.')\n",
    "    ax.scatter(np.tile(x, (len(particles[0]),1)).ravel(), particles[:,:,0].T, s=ws*1000/np.sqrt(len(ws)),\n",
    "                alpha=0.15, label='Particles')\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Observed\")\n",
    "    ax.legend()\n",
    "    \n",
    "def filter_plot(x, y, yn, pf, inputs=None):\n",
    "    \"\"\"Apply a filter to yn, and plot the results using plot_particles()\"\"\"\n",
    "    states = apply_filter(pf, yn, inputs)\n",
    "    plot_particles(x, y, yn, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy sine wave data\n",
    "x = np.linspace(0, 100, 100)\n",
    "y = np.cos(x/4.0) + x * 0.05\n",
    "yn = y + np.random.normal(0,0.5,x.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, label='True', lw=1)\n",
    "ax.plot(x, yn, label='Noisy', lw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No dynamics\n",
    "# just diffusion on x\n",
    "prior_fn = lambda n: np.random.normal(0,1,(n,1))\n",
    "dt = 0.05\n",
    "noise = 0.15\n",
    "sigma = 1.5\n",
    "\n",
    "pf = ParticleFilter(prior_fn = prior_fn, \n",
    "                    observe_fn = lambda x:  x,  \n",
    "                    dynamics_fn=lambda x:   x ,\n",
    "                    n_particles=250, \n",
    "                    noise_fn = lambda x: x + np.random.normal(0, noise, x.shape),\n",
    "                    weight_fn = lambda x,y : squared_error(x, y, sigma=sigma),\n",
    "                    resample_proportion=0.01)\n",
    "\n",
    "filter_plot(x, y, yn, pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umbridge-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
